---
title: grnn代码
published: 2025-04-01
description: ''
image: ''
tags: [works]
category: ''
draft: false 
lang: ''
---

##
```
import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import euclidean_distances
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.dummy import DummyRegressor
from tqdm.auto import tqdm
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import time

# ======================== 全局配置 ========================
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
os.makedirs("results", exist_ok=True)

# ======================== 自定义GRNN ========================
class CustomGRNN(BaseEstimator, RegressorMixin):
    def __init__(self, sigma=0.1, batch_size=1000):
        self.sigma = sigma
        self.batch_size = batch_size
        self.X_train = None
        self.y_train = None

    def fit(self, X, y):
        self.X_train = np.array(X)
        self.y_train = np.array(y)
        return self

    def predict(self, X):
        X = np.array(X)
        predictions = np.zeros(len(X))
        for i in range(0, len(X), self.batch_size):
            batch = X[i:i+self.batch_size]
            dist = euclidean_distances(batch, self.X_train)
            weights = np.exp(-dist**2 / (2 * self.sigma**2))
            weights_sum = np.sum(weights, axis=1, keepdims=True)
            weights_sum[weights_sum == 0] = 1e-10
            predictions[i:i+self.batch_size] = np.sum(weights * self.y_train, axis=1) / weights_sum.flatten()
        return predictions

# ======================== 数据加载 ========================
def load_station_coords(file_path="yunnan_stations.txt"):
    stations = {}
    with open(file_path, 'r') as f:
        for line in tqdm(f.readlines(), desc="加载测站坐标"):
            parts = line.strip().split()
            if len(parts) == 4:
                stations[parts[0]] = {
                    'lon': float(parts[1]),
                    'lat': float(parts[2]),
                    'height': float(parts[3])
                }
    return stations

def load_ztd_data(directory="ZTDfile"):
    data = []
    ztd_files = [f for f in os.listdir(directory) if f.endswith('.ztd')]
    for filename in tqdm(ztd_files, desc="加载ZTD数据"):
        with open(os.path.join(directory, filename), 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 8:
                    data.append({
                        'station': filename[:4],
                        'year': int(parts[0]),
                        'month': int(parts[1]),
                        'day': int(parts[2]),
                        'hour': int(parts[3]),
                        'minute': int(parts[4]),
                        'second': int(parts[5]),
                        'mjd': float(parts[6]),
                        'ztd': float(parts[7])
                    })
    return pd.DataFrame(data)

# ======================== 模型训练辅助函数 ========================
def train_model(X, y, model, model_name, scaler=None):
    print(f"\n===== Training {model_name} =====")
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=True
    )
    
    dummy = DummyRegressor(strategy='mean')
    dummy.fit(X_train, y_train)
    dummy_pred = dummy.predict(X_test)
    print(f"\n基线模型MSE: {mean_squared_error(y_test, dummy_pred):.6f}")
    
    with tqdm(total=1, desc="Training") as pbar:
        model.fit(X_train, y_train)
        pbar.update(1)
    
    cv_scores = cross_val_score(model, X, y, cv=5, 
                                scoring='neg_mean_squared_error')
    print(f"交叉验证MSE: {-cv_scores.mean():.6f} (±{cv_scores.std():.6f})")
    
    y_pred = model.predict(X_test)
    train_pred = model.predict(X_train)
    
    print(f"\n训练集 MSE: {mean_squared_error(y_train, train_pred):.6f}")
    print(f"测试集 MSE: {mean_squared_error(y_test, y_pred):.6f}")
    print(f"R²: {r2_score(y_test, y_pred):.4f}")
    
    with tqdm(total=2, desc="Saving Models") as pbar:
        if scaler is not None:
            scaler_data = {
                'mean_': scaler.mean_,
                'scale_': scaler.scale_,
                'var_': scaler.var_,
                'n_samples_seen_': scaler.n_samples_seen_
            }
            np.savez(f"results/{model_name}_scaler.npz", **scaler_data)
            pbar.update(1)
        
        joblib.dump(model, f"results/{model_name}_model.pkl", compress=3)
        pbar.update(1)
    
    return model, y_test, y_pred

# ======================== GRNN训练函数 ========================
def train_grnn(stations, ztd_df):
    # 数据准备
    with tqdm(total=6, desc="Preparing GRNN Data") as pbar:
        ztd_df['lon'] = ztd_df['station'].map(lambda x: stations[x]['lon'])
        pbar.update(1)
        ztd_df['lat'] = ztd_df['station'].map(lambda x: stations[x]['lat'])
        pbar.update(1)
        ztd_df['height'] = ztd_df['station'].map(lambda x: stations[x]['height'])
        pbar.update(1)
        sample_df = ztd_df.sample(min(100000, len(ztd_df)), random_state=42)  # 采样10,000条
        pbar.update(1)
        X = sample_df[['lon', 'lat', 'height', 'mjd']].values
        y = sample_df['ztd'].values
        pbar.update(1)
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        pbar.update(1)
    
    # 超参数调优
    with tqdm(total=1, desc="GRNN Tuning") as pbar:
        param_grid = {'sigma': [0.5, 1.0]}  # 减少sigma候选值
        grnn = GridSearchCV(
            CustomGRNN(),
            param_grid,
            cv=2,  # 2折交叉验证
            scoring='neg_mean_squared_error',
            verbose=1,
            n_jobs=1  # 单线程
        )
        print(f"开始GRNN超参数调优，数据量: {len(X)}")
        start_time = time.time()
        grnn.fit(X_scaled, y)
        end_time = time.time()
        print(f"GRNN超参数调优耗时: {end_time - start_time:.2f}秒")
        best_grnn = grnn.best_estimator_
        print(f"最佳参数: {grnn.best_params_}")
        pbar.update(1)
    
    # 模型训练
    model, y_test, y_pred = train_model(X_scaled, y, best_grnn, "GRNN", scaler)
    
    # 保存结果并可视化
    with tqdm(total=2, desc="Generating Results") as pbar:
        sample_df['pred_grnn'] = model.predict(X_scaled)
        pbar.update(1)
        plot_model_performance(y_test, y_pred, stations, sample_df, "GRNN")
        pbar.update(1)

# ======================== 绘图函数 ========================
def plot_model_performance(y_true, y_pred, stations, ztd_df, model_name):
    plt.figure(figsize=(20, 18))
    
    # 将数据转换为毫米（1 m = 1000 mm）
    y_true_mm = y_true * 1000
    y_pred_mm = y_pred * 1000
    
    # 动态计算显示范围（排除1%极端值）
    y_all_mm = np.concatenate([y_true_mm, y_pred_mm])
    lower, upper = np.percentile(y_all_mm, [1, 99])
    margin = (upper - lower) * 0.05
    
    # 子图1：预测 vs 真实值
    plt.subplot(3, 2, 1)
    sns.scatterplot(x=y_true_mm, y=y_pred_mm, alpha=0.5, s=20, color='#1f77b4')
    plt.plot([lower, upper], [lower, upper], 'r--', lw=2)
    plt.xlim(lower-margin, upper+margin)
    plt.ylim(lower-margin, upper+margin)
    plt.xlabel('True ZTD (mm)')
    plt.ylabel('Predicted ZTD (mm)')
    plt.title('Predicted vs True ZTD')
    
    # 添加统计指标（RMSE 转换为毫米）
    rmse_mm = np.sqrt(mean_squared_error(y_true_mm, y_pred_mm))
    r2 = r2_score(y_true_mm, y_pred_mm)
    plt.text(0.05, 0.9, f'RMSE: {rmse_mm:.4f} mm\nR²: {r2:.4f}', 
             transform=plt.gca().transAxes,
             bbox=dict(facecolor='white', alpha=0.8))

    # 子图2：残差分布
    plt.subplot(3, 2, 2)
    residuals_mm = y_true_mm - y_pred_mm
    ax = sns.histplot(residuals_mm, kde=True, color='#2ca02c', stat='probability', common_norm=True)
    plt.axvline(x=0, color='r', linestyle='--')
    plt.xlabel('Residuals (mm)')
    plt.ylabel('Proportion')
    plt.title('Residuals Distribution')
    
    # 子图3：误差分布箱线图
    plt.subplot(3, 2, 3)
    sns.boxplot(x=residuals_mm, color='#ff7f0e')
    plt.xlabel('Prediction Error (mm)')
    plt.title('Error Distribution')
    
    # 子图4：误差与真实值关系
    plt.subplot(3, 2, 4)
    sns.scatterplot(x=y_true_mm, y=residuals_mm, alpha=0.5, color='#d62728')
    plt.axhline(y=0, color='k', linestyle='--')
    plt.xlabel('True ZTD (mm)')
    plt.ylabel('Residuals (mm)')
    plt.title('Residuals vs True ZTD')
    
    # 子图5：Bias分布（自动计算 bins，与残差图样式一致）
    plt.subplot(3, 2, 5)
    ztd_df['bias'] = (ztd_df[f'pred_{model_name.lower()}'] - ztd_df['ztd']) * 1000
    bias_mm = ztd_df['bias'].values
    
    ax = sns.histplot(bias_mm, kde=True, color='#2ca02c', stat='probability', common_norm=True)
    plt.axvline(x=0, color='r', linestyle='--')
    plt.xlabel('Bias (Predicted - True) (mm)')
    plt.ylabel('Proportion')
    plt.title(f'{model_name} Bias Distribution')
    
    plt.tight_layout(pad=2.0)
    plt.savefig(f'results/{model_name}_performance.png', dpi=300, bbox_inches='tight')
    plt.close()

# ======================== 运行GRNN的函数 ========================
def run_grnn():
    print("======= 开始GRNN处理 =======")
    stations = load_station_coords()
    ztd_df = load_ztd_data()
    train_grnn(stations, ztd_df.copy())
    print("======= GRNN处理完成 =======")

if __name__ == "__main__":
    run_grnn()






```